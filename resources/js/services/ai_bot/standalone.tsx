import * as ort from 'onnxruntime-web/webgpu';
import type { AxiosInstance } from "axios";
/**
 * CONFIGURAZIONE
 */
const CONFIG = {
    modelPath: 'model_webgpu.onnx',
    imageFolder: 'images_256',
    attributeNames: [
        'smile',
        'gender_male',
        'gender_female',
        'hair_brown',
        'hair_black',
        'hair_blond',
        'hair_gray',
        'hair_long',
        'hair_short',
        'ethnicity_asian',
        'ethnicity_black',
        'ethnicity_latino',
        'ethnicity_white',
        'eye_blue',
        'eye_brown',
        'eye_green',
        'has_facial_hair',
        'a person with eyeglasses'
    ],
    attributeGroups: [
        { name: 'Gender', indices: [1, 2] },
        { name: 'Hair Color', indices: [3, 4, 5, 6] },
        { name: 'Hair Length', indices: [7, 8] },
        { name: 'Ethnicity', indices: [9, 10, 11, 12] },
        { name: 'Eye Color', indices: [13, 14, 15] }
    ],
    displayMapping: {
        0: 'Sorriso',
        1: 'Uomo',
        2: 'Donna',
        3: 'Capelli Marroni',
        4: 'Capelli Neri',
        5: 'Capelli Biondi',
        6: 'Capelli Grigi',
        7: 'Capelli Lunghi',
        8: 'Capelli Corti',
        9: 'Asiatico',
        10: 'Nero',
        11: 'Latino',
        12: 'Bianco',
        13: 'Occhi Azzurri',
        14: 'Occhi Marroni',
        15: 'Occhi Verdi',
        16: 'Con Barba',
        17: 'Con Occhiali'
    },
    // Mapping domanda -> tratto -> indici attributi originali
    questionToIndices: {
        0: [0],              // Sorriso
        1: [1],              // Uomo
        2: [2],              // Donna
        3: [3],              // Capelli Marroni
        4: [4],              // Capelli neri
        5: [5],              // Capelli biondi
        6: [6],              // Capelli grigi
        7: [7],              // Capelli lunghi
        8: [8],              // Capelli corti
        9: [9],              // Etnia asiatico
        10: [10],            // Etnia africano
        11: [11],            // Etnia latino
        12: [12],            // Etnia caucasica
        13: [13],            // Occhi azzurri
        14: [14],            // Occhi marroni
        15: [15],            // Occhi verdi
        16: [16],            // Con Barba
        17: [17]             // Con Occhiali
    } as Record<number, number[]>
    };


/**
 * TIPI
 */
type Attribute = {
  name: string | undefined;
  probability: number;
  rawValue: number;
  index: number;
  displayName?: string;
};

export type QuestionAnswer = {
  questionId: number;
  answer: boolean;
  percentage: number;
};

/**
 * CLASSE PRINCIPALE CON SUPPORTO WEBGPU
 */
export class FacialAttributesClassifier {
    private static instance: FacialAttributesClassifier | null = null;
    private session: ort.InferenceSession | null = null;
    private executionProvider: string = '';

    public constructor() {}

    public static getInstance(): FacialAttributesClassifier {
        if (!FacialAttributesClassifier.instance) {
            FacialAttributesClassifier.instance = new FacialAttributesClassifier();
        }
        return FacialAttributesClassifier.instance;
    }


  /**
   * Carica il modello con supporto WebGPU e Cache API
   * @param useWebGpu - Se true, tenta di usare WebGPU, altrimenti usa WASM
   * @param modelPath - Percorso personalizzato del modello (opzionale)
   */
async loadModel(useWebGpu: boolean = true, modelPath?: string, axios?: AxiosInstance): Promise<void> {
    const mPath = modelPath || CONFIG.modelPath;
    const CACHE_NAME = 'ai-model-cache-v1';

    try {
        const sessionOptions: ort.InferenceSession.SessionOptions = {
            executionProviders: [],
            graphOptimizationLevel: 'all',
        };

        let modelBuffer: ArrayBuffer;

        // Prova SEMPRE a caricare dalla cache (se disponibile)
        if ('caches' in window) {
            try {
                const cache = await caches.open(CACHE_NAME);
                let cachedResponse = await cache.match(mPath);

                if (cachedResponse) {
                    // ‚úÖ Trovato in cache!
                    console.log('‚úÖ Model loaded from cache!');
                    modelBuffer = await cachedResponse.arrayBuffer();
                } else {
                    // ‚ùå Non in cache, scarica (con axios o fetch)
                    console.log('üì• Downloading model (first time)...');

                    if (axios) {
                        // Scarica con axios
                        const modelResponse = await axios.get(mPath, { responseType: "arraybuffer" });
                        modelBuffer = modelResponse.data;

                        // Salva in cache creando una Response da ArrayBuffer
                        const blob = new Blob([modelBuffer]);
                        const response = new Response(blob);
                        await cache.put(mPath, response);
                        console.log('üíæ Model cached successfully (from axios)!');
                    } else {
                        // Scarica con fetch
                        const response = await fetch(mPath);

                        if (!response.ok) {
                            throw new Error(`Failed to fetch model: ${response.status}`);
                        }

                        await cache.put(mPath, response.clone());
                        console.log('üíæ Model cached successfully (from fetch)!');

                        modelBuffer = await response.arrayBuffer();
                    }
                }
            } catch (cacheError) {
                console.warn('‚ö†Ô∏è  Cache error, falling back to direct download:', cacheError);

                // Fallback senza cache
                if (axios) {
                    const modelResponse = await axios.get(mPath, { responseType: "arraybuffer" });
                    modelBuffer = modelResponse.data;
                } else {
                    const response = await fetch(mPath);
                    modelBuffer = await response.arrayBuffer();
                }
            }
        } else {
            // Browser non supporta Cache API
            if (axios) {
                const modelResponse = await axios.get(mPath, { responseType: "arraybuffer" });
                modelBuffer = modelResponse.data;
            } else {
                const response = await fetch(mPath);
                modelBuffer = await response.arrayBuffer();
            }
        }



      // Determina quale execution provider utilizzare
      if (useWebGpu) {
        // Verifica supporto WebGPU
        if ('gpu' in navigator) {
          try {
            const adapter = await (navigator as any).gpu.requestAdapter();
            if (adapter) {
              console.log('‚úÖ WebGPU supported, attempting to use it...');
              sessionOptions.executionProviders = ['webgpu'];
            } else {
              console.warn('‚ö†Ô∏è  WebGPU not available, falling back to WASM');
              sessionOptions.executionProviders = ['wasm'];
            }
          } catch (err) {
            console.warn('‚ö†Ô∏è  WebGPU check failed, using WASM:', err);
            sessionOptions.executionProviders = ['wasm'];
          }
        } else {
          console.warn('‚ö†Ô∏è  WebGPU not supported by browser, using WASM');
          sessionOptions.executionProviders = ['wasm'];
        }
      } else {
        console.log('üîÑ Using WASM (CPU) as requested');
        sessionOptions.executionProviders = ['wasm'];
      }

      // Crea la sessione
      this.session = await ort.InferenceSession.create(modelBuffer, sessionOptions);

      // Verifica quale provider √® stato effettivamente utilizzato
      this.executionProvider = (this.session as any).handler?._ep ||
                              sessionOptions.executionProviders[0] ||
                              'unknown';

      console.log('‚úÖ Model loaded successfully');
      console.log(`üéÆ Execution provider: ${this.executionProvider}`);

    } catch (error) {
      throw new Error(`Failed to load model: ${error}`);
    }
  }

  /**
   * Pre-processa un'immagine 256x256 per il modello
   */
  private async preprocessImage(imageUrl: string): Promise<ort.Tensor> {
    return new Promise<ort.Tensor>((resolve, reject) => {
      const img = new Image();
      img.crossOrigin = 'anonymous';

      img.onload = () => {
        try {
          const canvas = document.createElement('canvas');
          canvas.width = 256;
          canvas.height = 256;
          const ctx = canvas.getContext('2d');

          if (!ctx) {
            reject(new Error('Unable to obtain 2D rendering context'));
            return;
          }

          ctx.drawImage(img, 0, 0, 256, 256);
          const imageData = ctx.getImageData(0, 0, 256, 256);
          const data = imageData.data;

          const red: number[] = [], green: number[] = [], blue: number[] = [];

          for (let i = 0; i < data.length; i += 4) {
            const r = data[i] ?? 0;
            const g = data[i + 1] ?? 0;
            const b = data[i + 2] ?? 0;

            red.push(r / 255.0);
            green.push(g / 255.0);
            blue.push(b / 255.0);
          }

          const input = new Float32Array([...red, ...green, ...blue]);
          const tensor = new ort.Tensor('float32', input, [1, 3, 256, 256]);

          resolve(tensor);
        } catch (err) {
          reject(err instanceof Error ? err : new Error(String(err)));
        }
      };

      img.onerror = () => reject(new Error(`Failed to load image: ${imageUrl}`));
      img.src = imageUrl;
    });
  }

  /**
   * Ottiene gli attributi dominanti per ogni gruppo
   */
  private getDominantAttributes(attributes: Attribute[]): Map<string, number> {
    const dominantMap = new Map<string, number>();

    // Processa i gruppi di attributi mutualmente esclusivi
    for (const group of CONFIG.attributeGroups) {
      let maxProb = -1;
      let maxAttr: Attribute | undefined = undefined;

      for (const idx of group.indices) {
        const attr = attributes.find(a => a.index === idx);
        if (attr && attr.probability > maxProb) {
          maxProb = attr.probability;
          maxAttr = attr;
        }
      }

      if (maxAttr) {
        const displayName = CONFIG.displayMapping[maxAttr.index as keyof typeof CONFIG.displayMapping];
        if (displayName) {
          dominantMap.set(displayName, maxAttr.probability);
        }
      }
    }

    // Aggiungi attributi non in gruppi (smile, facial hair, eyeglasses)
    const usedIndices = new Set<number>();
    CONFIG.attributeGroups.forEach(g => g.indices.forEach(i => usedIndices.add(i)));

    for (const attr of attributes) {
      if (!usedIndices.has(attr.index)) {
        const displayName = CONFIG.displayMapping[attr.index as keyof typeof CONFIG.displayMapping];
        if (displayName) {
          dominantMap.set(displayName, attr.probability);
        }
      }
    }

    return dominantMap;
  }

  /**
   * Calcola la probabilit√† massima per una domanda basandosi sugli indici corrispondenti
   */
  private getQuestionProbability(questionId: number, attributes: Attribute[]): number {
    const indices = CONFIG.questionToIndices[questionId];
    if (!indices || indices.length === 0) {
      return 0;
    }

    let maxProb = 0;
    for (const idx of indices) {
      const attr = attributes.find(a => a.index === idx);
      if (attr && attr.probability > maxProb) {
        maxProb = attr.probability;
      }
    }

    return maxProb;
  }

  /**
   * Verifica se un nome inizia con vocale
   */
  private startsWithVowel(name?: string): boolean {
    if (!name) return false;
    const firstChar = name.charAt(0).toLowerCase();
    return ['a', 'e', 'i', 'o', 'u'].includes(firstChar);
  }

  /**
   * METODO CENTRALE: Classifica una singola immagine e restituisce array di 19 risposte
   *
   * @param imageSrc - URL o percorso dell'immagine da classificare
   * @param imageName - Nome opzionale dell'immagine (usato per domande vocale/consonante)
   * @returns Array di QuestionAnswer con 19 elementi
   */
  public async classifyImage(imageSrc: string, imageName?: string): Promise<QuestionAnswer[]> {
    if (!this.session) {
      throw new Error('Model not loaded. Call loadModel() first.');
    }

    console.log(`\nüñºÔ∏è  Classifying: ${imageName || imageSrc}`);
    console.log('‚îÅ'.repeat(60));

    try {
      // Pre-processa l'immagine
      console.log('‚öôÔ∏è  Preprocessing image...');
      const tensor = await this.preprocessImage(imageSrc);

      // Esegui l'inferenza (WebGPU o WASM)
      console.log(`üß† Running inference (${this.executionProvider})...`);
      const feeds: Record<string, ort.Tensor> = {};
      const inputName = this.session.inputNames && this.session.inputNames.length > 0
        ? this.session.inputNames[0]
        : 'input';

      if (inputName) {
        feeds[inputName] = tensor;
      }

      const output = await this.session.run(feeds);
      const outputName = this.session.outputNames && this.session.outputNames.length > 0
        ? this.session.outputNames[0]
        : Object.keys(output)[0];

      if (!outputName) {
        throw new Error('Unable to determine output name');
      }

      const outputTensor = output[outputName];
      if (!outputTensor) {
        throw new Error('Output tensor is undefined');
      }

      const predictions = outputTensor.data as ArrayLike<number>;
      console.log(`üìä Received ${predictions.length} predictions`);

      // Crea gli attributi con sigmoide
      const attributes: Attribute[] = [];
      for (let i = 0; i < predictions.length && i < CONFIG.attributeNames.length; i++) {
        const pred = predictions[i];
        if (pred !== undefined && pred !== null) {
          const probability = 1 / (1 + Math.exp(-pred));
          attributes.push({
            name: CONFIG.attributeNames[i],
            probability,
            rawValue: pred,
            index: i
          });
        }
      }

      // Ottieni i tratti dominanti
      const dominantTraits = this.getDominantAttributes(attributes);

      // Costruisci l'array di 19 risposte
      const answers: QuestionAnswer[] = [];
      const isVowel = this.startsWithVowel(imageName);
      const numQuestions = 19;

      for (let questionId = 0; questionId <= numQuestions; questionId++) {
        if (questionId === (numQuestions - 1)) {
          // Penultima domanda: "Ha un nome che inizia con una vocale?"
          answers.push({
            questionId,
            answer: isVowel,
            percentage: isVowel ? 100 : 0
          });
        } else if (questionId === numQuestions) {
          // Ultima domanda: "Ha un nome che inizia con una consonante?"
          answers.push({
            questionId,
            answer: !isVowel,
            percentage: !isVowel ? 100 : 0
          });
        } else {
          // Attributi dal modello (questionId 0-17)
          const indices = CONFIG.questionToIndices[questionId];
          if (indices && indices.length > 0) {
            const probability = this.getQuestionProbability(questionId, attributes);
            const percentage = Math.round(probability * 100);

            // Determina se la risposta √® true
            let answer = false;

            // Attributi non raggruppati (Sorriso, Barba, Occhiali): usa soglia 50%
            if (questionId === 0 || questionId === 16 || questionId === 17) {
              answer = probability > 0.5;
            } else {
              // Attributi raggruppati: controlla i tratti dominanti
              for (const [displayName] of Array.from(dominantTraits.entries())) {
                const displayIndices = indices.map(idx =>
                  CONFIG.displayMapping[idx as keyof typeof CONFIG.displayMapping]
                );
                if (displayIndices.includes(displayName)) {
                  answer = true;
                  break;
                }
              }
            }

            answers.push({
              questionId,
              answer,
              percentage
            });
          } else {
            // Attributo non presente
            answers.push({
              questionId,
              answer: false,
              percentage: 0
            });
          }
        }
      }

      // Stampa risultati su console
      this.printResults(answers, imageName || imageSrc);

      return answers;

    } catch (err) {
      const message = err instanceof Error ? err.message : String(err);
      throw new Error(`Failed to classify image: ${message}`);
    }
  }

  /**
   * Versione alternativa che accetta imageId invece di percorso completo
   */
  public async classifyImageById(imageId: number, imageName?: string): Promise<QuestionAnswer[]> {
    const paddedNumber = String(imageId).padStart(6, '0');
    const imageUrl = `${CONFIG.imageFolder}/${paddedNumber}.jpg`;
    return this.classifyImage(imageUrl, imageName);
  }

  /**
   * Stampa i risultati su console in formato leggibile
   */
  private printResults(answers: QuestionAnswer[], imageName: string): void {
    console.log(`\nüìã Results for: ${imageName}`);
    console.log('‚ïê'.repeat(60));

    const questionLabels: Record<number, string> = {
      0: 'Sorriso',
      1: 'Uomo',
      2: 'Donna',
      3: 'Capelli Marroni',
      4: 'Capelli Neri',
      5: 'Capelli Biondi',
      6: 'Capelli Grigi',
      7: 'Capelli Lunghi',
      8: 'Capelli Corti',
      9: 'Asiatico',
      10: 'Nero',
      11: 'Latino',
      12: 'Bianco',
      13: 'Occhi Azzurri',
      14: 'Occhi Marroni',
      15: 'Occhi Verdi',
      16: 'Con Barba',
      17: 'Con Occhiali',
      18: 'Nome con Vocale',
      19: 'Nome con Consonante'
    };

    answers.forEach((qa) => {
      const label = questionLabels[qa.questionId] || `Q${qa.questionId}`;
      const answerStr = qa.answer ? '‚úì S√¨' : '‚úó No';
      const bar = '‚ñà'.repeat(Math.round(qa.percentage / 10));

      console.log(
        `${String(qa.questionId).padStart(2)}. ${label.padEnd(20)} ‚Üí ${answerStr.padEnd(6)} [${bar.padEnd(10)}] ${qa.percentage}%`
      );
    });

    console.log('‚ïê'.repeat(60));
  }

  /**
   * Restituisce il provider di esecuzione attualmente in uso
   */
  public getExecutionProvider(): string {
    return this.executionProvider;
  }

  /**
   * Pulisce la cache del modello (utile per aggiornamenti)
   */
  public static async clearModelCache(cacheName: string = 'ai-model-cache-v1'): Promise<void> {
    if ('caches' in window) {
      const deleted = await caches.delete(cacheName);
      if (deleted) {
        console.log(`üóëÔ∏è  Cache "${cacheName}" cleared successfully`);
      } else {
        console.log(`‚ÑπÔ∏è  Cache "${cacheName}" not found or already cleared`);
      }
    }
  }

  /**
   * Verifica se il modello √® presente in cache
   */
  public static async isModelCached(modelPath: string = CONFIG.modelPath, cacheName: string = 'ai-model-cache-v1'): Promise<boolean> {
    if ('caches' in window) {
      const cache = await caches.open(cacheName);
      const response = await cache.match(modelPath);
      return response !== undefined;
    }
    return false;
  }
}

/**
 * FUNZIONE DI UTILIT√Ä: Crea classificatore e classifica immagine per ID
 */
export async function classifyImageById(
  imageId: number,
  imageName?: string,
  options?: {
    modelPath?: string;
    useWebGpu?: boolean;
  }
): Promise<QuestionAnswer[]> {
  const classifier = new FacialAttributesClassifier();
  await classifier.loadModel(options?.useWebGpu ?? true, options?.modelPath);
  const answers = await classifier.classifyImageById(imageId, imageName);

  //console.log(`\n‚úÖ Classification completed using: ${classifier.getExecutionProvider()}\n`);

  return answers;
}

/**
 * FUNZIONE DI UTILIT√Ä: Crea classificatore e classifica immagine per percorso
 */
export async function classifyImage(
  imageSrc: string,
  imageName?: string,
  options?: {
    modelPath?: string;
    useWebGpu?: boolean;
  }
): Promise<QuestionAnswer[]> {
  const classifier = new FacialAttributesClassifier();
  await classifier.loadModel(options?.useWebGpu ?? true, options?.modelPath);
  const answers = await classifier.classifyImage(imageSrc, imageName);

  //console.log(`\n‚úÖ Classification completed using: ${classifier.getExecutionProvider()}\n`);

  return answers;
}
